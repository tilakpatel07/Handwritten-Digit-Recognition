{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322616ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct \n",
    "\n",
    "#This reads the MNIST dataset files in IDX1 format.\n",
    "def read_idx1_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_of_labels = struct.unpack('>II', f.read(8))\n",
    "        assert magic == 2049, f\"Expected magic number 2049, got {magic}\"\n",
    "\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "#This reads the MNIST dataset files in IDX3 format.\n",
    "def read_idx3_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_of_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        assert magic == 2051, f\"Expected magic number 2051, got {magic}\"\n",
    "\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num_of_images, rows, cols)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d01225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the MNIST dataset\n",
    "train_labels = read_idx1_file('handwritten_numbers_dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "train_images = read_idx3_file('handwritten_numbers_dataset/train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "\n",
    "test_labels = read_idx1_file('handwritten_numbers_dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "test_images = read_idx3_file('handwritten_numbers_dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3408de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to the range [0, 1] for better training performance\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8bf939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images to be 2D arrays\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "test_images = test_images.reshape(test_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d9a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images, Val_images, train_labels, Val_labels = train_test_split(train_images, train_labels, test_size=0.1667, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fedff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Validation Accuracy: 0.943011397720456\n",
      "SVM - Validation F1-Score: 0.942856096943864\n",
      "SVM - Test Accuracy: 0.9447\n",
      "SVM - Test F1-Score: 0.9445740358444961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#hyperparameter tuning for SVM and Logistic Regression\n",
    "\n",
    "# Parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# Create a SVM classifier\n",
    "svc = SVC()\n",
    "grid_svc = GridSearchCV(svc, param_grid_svm, cv=5)\n",
    "grid_svc.fit(train_images, train_labels)\n",
    "\n",
    "#Best SVM model\n",
    "best_svc = grid_svc.best_estimator_\n",
    "\n",
    "# Evaluate the best SVM model on the validation set\n",
    "val_predictions_svm = best_svc.predict(Val_images)\n",
    "val_accuracy_svm = accuracy_score(Val_labels, val_predictions_svm)\n",
    "val_f1_svm = f1_score(Val_labels, val_predictions_svm, average='weighted')\n",
    "\n",
    "print(\"SVM - Validation Accuracy:\", val_accuracy_svm)\n",
    "print(\"SVM - Validation F1-Score:\", val_f1_svm)\n",
    "\n",
    "# Evaluate the best SVM model on the test set\n",
    "test_predictions_svm = best_svc.predict(test_images)\n",
    "test_accuracy_svm = accuracy_score(test_labels, test_predictions_svm)\n",
    "test_f1_svm = f1_score(test_labels, test_predictions_svm, average='weighted')\n",
    "\n",
    "print(\"SVM - Test Accuracy:\", test_accuracy_svm)\n",
    "print(\"SVM - Test F1-Score:\", test_f1_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726a20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving my model \n",
    "\n",
    "import pickle\n",
    "import logging  # It's good to log these operations\n",
    "\n",
    "def save_model(model, filename):\n",
    "    \"\"\"Saves the model to a pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'wb') as f:  # 'wb' mode for writing binary files\n",
    "            pickle.dump(model, f)\n",
    "        logging.info(f\"Model saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving model: {e}\", exc_info=True)  # Log the full error\n",
    "\n",
    "# Example usage after training your model:\n",
    "save_model(best_svc, \"my_trained_svm_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handwritten_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
