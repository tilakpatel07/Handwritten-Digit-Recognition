{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac653256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct \n",
    "\n",
    "#This reads the MNIST dataset files in IDX1 format.\n",
    "def read_idx1_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_of_labels = struct.unpack('>II', f.read(8))\n",
    "        assert magic == 2049, f\"Expected magic number 2049, got {magic}\"\n",
    "\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "#This reads the MNIST dataset files in IDX3 format.\n",
    "def read_idx3_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_of_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        assert magic == 2051, f\"Expected magic number 2051, got {magic}\"\n",
    "\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num_of_images, rows, cols)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa120bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the MNIST dataset\n",
    "train_labels = read_idx1_file('handwritten_numbers_dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "train_images = read_idx3_file('handwritten_numbers_dataset/train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "\n",
    "test_labels = read_idx1_file('handwritten_numbers_dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "test_images = read_idx3_file('handwritten_numbers_dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f52f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to the range [0, 1] for better training performance\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ba88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images to be 2D arrays\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "test_images = test_images.reshape(test_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa2f5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d3efcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7062b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images, Val_images, train_labels, Val_labels = train_test_split(train_images, train_labels, test_size=0.1667, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d17e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Validation Accuracy: 0.9236152769446111\n",
      "Logistic Regression - Validation F1-Score: 0.9234478331801074\n",
      "Logistic Regression - Test Accuracy: 0.9247\n",
      "Logistic Regression - Test F1-Score: 0.9245159783642534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#hyperparameter tuning for SVM and Logistic Regression\n",
    "\n",
    "# Parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "log_reg = LogisticRegression()\n",
    "grid_lr = GridSearchCV(log_reg, param_grid_lr, cv=5)\n",
    "grid_lr.fit(train_images, train_labels)\n",
    "\n",
    "#  Best LR model\n",
    "best_lr_model = grid_lr.best_estimator_\n",
    "\n",
    "# Evaluate the best Logistic Regression model on the validation set\n",
    "val_predictions_lr = best_lr_model.predict(Val_images)\n",
    "val_accuracy_lr = accuracy_score(Val_labels, val_predictions_lr)\n",
    "val_f1_lr = f1_score(Val_labels, val_predictions_lr, average='weighted') \n",
    "\n",
    "print(\"Logistic Regression - Validation Accuracy:\", val_accuracy_lr)\n",
    "print(\"Logistic Regression - Validation F1-Score:\", val_f1_lr)\n",
    "\n",
    "# Evaluate the best Logistic Regression model on the test set\n",
    "test_predictions_lr = best_lr_model.predict(test_images)\n",
    "test_accuracy_lr = accuracy_score(test_labels, test_predictions_lr)\n",
    "test_f1_lr = f1_score(test_labels, test_predictions_lr, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression - Test Accuracy:\", test_accuracy_lr)\n",
    "print(\"Logistic Regression - Test F1-Score:\", test_f1_lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017d1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving my model \n",
    "\n",
    "import pickle\n",
    "import logging  # It's good to log these operations\n",
    "\n",
    "def save_model(model, filename):\n",
    "    \"\"\"Saves the model to a pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'wb') as f:  # 'wb' mode for writing binary files\n",
    "            pickle.dump(model, f)\n",
    "        logging.info(f\"Model saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving model: {e}\", exc_info=True)  # Log the full error\n",
    "\n",
    "# Example usage after training your model:\n",
    "save_model(best_lr_model, \"my_trained_logistic_regression.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handwritten_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
